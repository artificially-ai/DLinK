{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulding a Convolutional Neural Network to classify Zalando's MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://www.github.com/ekholabs/keras-contrib.git@improve-sinerelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer, Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, LeakyReLU, BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras_contrib.layers.advanced_activations import SineReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data\n",
    "Flatten and normalise input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")/255.\n",
    "X_test = X_test.astype(\"float32\")/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoded categories\n",
    "n_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_cnn, epsilon_dense = 0.025, 0.006\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, 7, padding = 'same', input_shape = (28, 28, 1)))\n",
    "# model.add(SineReLU(epsilon_cnn))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, 7, padding = 'same'))\n",
    "# model.add(SineReLU(epsilon_cnn))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding = 'same'))\n",
    "# model.add(SineReLU(epsilon_cnn))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding = 'same'))\n",
    "# model.add(SineReLU(epsilon_cnn))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Conv2D(128, 2, padding = 'same'))\n",
    "# model.add(SineReLU(epsilon_cnn))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, 2, padding = 'same'))\n",
    "# model.add(SineReLU(epsilon_cnn))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "# model.add(SineReLU(epsilon_dense))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = ModelCheckpoint(monitor='val_acc', filepath='model_output/weights-cnn-mnist.hdf5',\n",
    "                                               save_best_only=True, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', mode='max', patience=30)\n",
    "\n",
    "\n",
    "if not os.path.exists('model_output'):\n",
    "    os.makedirs('model_output')\n",
    "\n",
    "tensorboard = TensorBoard(\"../new_logs/convnet-mnist-relu-VIII\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 128, epochs = 40, verbose = 1,\n",
    "          validation_split = 0.1, callbacks=[modelCheckpoint, earlyStopping, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = keras.models.load_model('model_output/weights-cnn-mnist.hdf5')\n",
    "predictions = saved_model.predict_classes(X_test, verbose = 2)\n",
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss, final_acc = saved_model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))\n",
    "final_loss, final_acc = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
