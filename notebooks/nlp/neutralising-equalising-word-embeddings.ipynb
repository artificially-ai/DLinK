{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutralising and Equalising Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how non-gender specific words can have the gender part neutralised to avoid bias in word embeddings. In addition to that, it also depicts the process of equalisation, where words that are gender-specific can be equalised towards words that are non-gender specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the GloVe dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloVe dataset is not part of the repository due to the size of the file. However, feel free to download it from here: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word_to_vec_map = read_glove_vecs('glove/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* words: set of words in the vocabulary.\n",
    "* word_to_vec_map: dictionary mapping words to their GloVe vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Cosine similarity reflects the degree of similariy between u and v\n",
    "        \n",
    "    Arguments:\n",
    "        u -- a word vector of shape (n,)          \n",
    "        v -- a word vector of shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    dot = np.dot(u, v)\n",
    "    norm_u = np.sqrt(np.sum(u**2))    \n",
    "    norm_v = np.sqrt(np.sum(v**2))\n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.8909038442893615\n",
      "cosine_similarity(ball, crocodile) =  0.2743924626137942\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.6751479308174201\n",
      "cosine_similarity(paris - france, rome - italy) =  0.6751479308174201\n"
     ]
    }
   ],
   "source": [
    "father = word_to_vec_map[\"father\"]\n",
    "mother = word_to_vec_map[\"mother\"]\n",
    "ball = word_to_vec_map[\"ball\"]\n",
    "crocodile = word_to_vec_map[\"crocodile\"]\n",
    "\n",
    "france = word_to_vec_map[\"france\"]\n",
    "italy = word_to_vec_map[\"italy\"]\n",
    "paris = word_to_vec_map[\"paris\"]\n",
    "rome = word_to_vec_map[\"rome\"]\n",
    "\n",
    "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
    "print(\"cosine_similarity(ball, crocodile) = \", cosine_similarity(ball, crocodile))\n",
    "\n",
    "# This should not show similarity as in the first vector we subtract the city representation\n",
    "# and in the second we subtract the country representation.\n",
    "print(\"cosine_similarity(france - paris, rome - italy) = \", cosine_similarity(france - paris, rome - italy))\n",
    "\n",
    "# This one, on the other hand, should show similarity as we are checking for the similarity between 2 cities.\n",
    "print(\"cosine_similarity(paris - france, rome - italy) = \", cosine_similarity(paris - france, rome - italy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by identifying the gender by subtracting the `man` vector representation from the `woman` vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = word_to_vec_map['woman'] - word_to_vec_map['man']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity between gender and names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative similarities mean that the name is more related to the `female` gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john -0.23163356145973724\n",
      "marie 0.315597935396073\n",
      "sophie 0.31868789859418784\n",
      "ronaldo -0.31244796850329437\n",
      "priya 0.17632041839009402\n",
      "rahul -0.16915471039231716\n",
      "danielle 0.24393299216283895\n",
      "reza -0.07930429672199553\n",
      "katy 0.2831068659572615\n",
      "yasmin 0.23313857767928758\n",
      "sam -0.33642281213435427\n",
      "carolina 0.0938795106708001\n",
      "logan -0.16937077820548485\n"
     ]
    }
   ],
   "source": [
    "name_list = ['john', 'marie', 'sophie',\n",
    "             'ronaldo', 'priya', 'rahul',\n",
    "             'danielle', 'reza', 'katy',\n",
    "             'yasmin', 'sam', 'carolina',\n",
    "             'logan']\n",
    "\n",
    "for w in name_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, non-gender specific words contain bias and hence need some extra treatment. Below a list of common words that look pretty biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipstick 0.2769191625638267\n",
      "driver -0.010681433817247916\n",
      "science -0.06082906540929701\n",
      "arts 0.008189312385880337\n",
      "literature 0.06472504433459932\n",
      "warrior -0.20920164641125288\n",
      "doctor 0.11895289410935041\n",
      "librarian 0.23302221769690296\n",
      "receptionist 0.33077941750593737\n",
      "technology -0.13193732447554302\n",
      "fashion 0.03563894625772699\n",
      "teacher 0.17920923431825664\n",
      "engineer -0.0803928049452407\n",
      "pilot 0.0010764498991916937\n",
      "computer -0.10330358873850498\n",
      "singer 0.1850051813649629\n",
      "model 0.0343357596036095\n",
      "mechanic -0.0035264430229621927\n",
      "babysitter 0.2797785047879521\n"
     ]
    }
   ],
   "source": [
    "word_list = ['lipstick', 'driver', 'science', 'arts',\n",
    "             'literature', 'warrior','doctor', 'librarian',\n",
    "             'receptionist', 'technology',  'fashion', 'teacher',\n",
    "             'engineer', 'pilot', 'computer', 'singer',\n",
    "             'model', 'mechanic', 'babysitter']\n",
    "for w in word_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, positive similarities relates to women whislt negative similaties don't. It's shocking to see that `computer`, `technology` and `engineer` do not relate to women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutralise bias for non-gender specific words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula below is used to compute the debiased version of a given vector representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "v^{bias\\_component} = \\frac{v \\cdot gender}{\\|gender\\|_2^2}gender \\\\\n",
    "\\\\\n",
    "v^{debiased} = v - v^{bias\\_component} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the implementation of the `neutralise` formula below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize(word, gender, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Removes the bias of \"word\" by projecting it on the space orthogonal to the bias axis. \n",
    "    This function ensures that gender neutral words are zero in the gender subspace.\n",
    "    \n",
    "    Arguments:\n",
    "        word -- string indicating the word to debias\n",
    "        gender -- numpy-array of shape (50,), corresponding to the bias axis (such as gender)\n",
    "        word_to_vec_map -- dictionary mapping words to their corresponding vectors.\n",
    "    \n",
    "    Returns:\n",
    "        v_debiased -- neutralised word vector representation of the input \"word\"\n",
    "    \"\"\"\n",
    "    \n",
    "    v = word_to_vec_map[word]\n",
    "    \n",
    "    v_biascomponent = (np.dot(v, gender) / np.sqrt(np.sum(gender**2))**2) * gender\n",
    "    v_debiased = v - v_biascomponent\n",
    "    \n",
    "    return v_debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity between receptionist and gender, before neutralizing:  0.33077941750593737\n",
      "cosine similarity between receptionist and gender, after neutralizing:  -2.099120994400013e-17\n"
     ]
    }
   ],
   "source": [
    "w = \"receptionist\"\n",
    "print(\"cosine similarity between \" + w + \" and gender, before neutralizing: \", cosine_similarity(word_to_vec_map[\"receptionist\"], gender))\n",
    "\n",
    "v_debiased = neutralize(\"receptionist\", gender, word_to_vec_map)\n",
    "print(\"cosine similarity between \" + w + \" and gender, after neutralizing: \", cosine_similarity(v_debiased, gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neutralised result is essentially 0, up to numerical roundof (on the order of  $10^{âˆ’17}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
